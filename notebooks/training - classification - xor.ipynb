{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from minitorch.autodiff import Scalar\n",
    "import minitorch.autodiff.tensor_functions as tf\n",
    "import minitorch.datasets as data\n",
    "from minitorch.module import ScalarNetwork, TensorNetwork\n",
    "from minitorch.optim import SGDOptimizer\n",
    "import minitorch.scalar_metrics as sm\n",
    "import minitorch.scalar_losses as sl\n",
    "import minitorch.tensor_losses as tl\n",
    "import minitorch.tensor_metrics as tm\n",
    "from minitorch.scalar_plotting import plot_scalar_predictions\n",
    "from minitorch.tensor_plotting import plot_tensor_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e29f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "N_SAMPLES = 50\n",
    "dataset = data.XORDataset(N_SAMPLES)\n",
    "dataset.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a233a3b",
   "metadata": {},
   "source": [
    "### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a network\n",
    "network = ScalarNetwork(input_dim=2, hidden_dim=10, output_dim=1)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = SGDOptimizer(parameters=network.parameters(), lr=0.3)\n",
    "\n",
    "# Data\n",
    "X = [list(x) for x in dataset.xs]\n",
    "y_true = dataset.ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 150\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    \n",
    "    # Zero all grads\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward\n",
    "    y_hat = network.forward(X)\n",
    "\n",
    "    # Convert to binary class probabilties\n",
    "    y_hat = [[scalar.sigmoid() for scalar in row] for row in y_hat]\n",
    "    y_hat = list(itertools.chain.from_iterable(y_hat))\n",
    "    \n",
    "    # Compute a loss\n",
    "    loss_per_epoch = sl.binary_cross_entropy(y_true, y_hat)\n",
    "    loss_per_epoch.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record\n",
    "    losses.append(loss_per_epoch.data)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch}: loss = {loss_per_epoch.data}\")\n",
    "\n",
    "    if epoch + 1 == n_epochs:\n",
    "        print(f\"epoch {epoch + 1}: loss = {loss_per_epoch.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d29f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "y_true = [Scalar(y_t) for y_t in y_true]\n",
    "y_hat = [[scalar.sigmoid() for scalar in row] for row in network.forward(X)]\n",
    "y_hat = list(itertools.chain.from_iterable(y_hat))\n",
    "\n",
    "# Convert to classes using 0.5 threshold\n",
    "y_hat_classes = [Scalar(1.0) if proba.data >= 0.5 else Scalar(0.0) for proba in y_hat]\n",
    "\n",
    "{\n",
    "    f.__name__: f(y_true=y_true, y_hat=y_hat_classes)\n",
    "    for f in [sm.accuracy, sm.precision, sm.recall]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "tpr, fpr, thresholds = sm.roc_curve(y_true, y_hat, bucket_size=0.001)\n",
    "tpr, fpr = [s.data for s in tpr], [s.data for s in fpr]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=110)\n",
    "ax.plot(fpr, tpr, \"-o\", c=\"tab:blue\")\n",
    "ax.plot([0, 1], [0, 1], ls=\"--\", c=\"tab:grey\")\n",
    "ax.set_xlabel(\"fpr\")\n",
    "ax.set_ylabel(\"tpr\")\n",
    "ax.set_title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising predictions\n",
    "plot_scalar_predictions(dataset, network);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de0389",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a network\n",
    "network = TensorNetwork(input_dim=2, hidden_dim=10, output_dim=1)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = SGDOptimizer(parameters=network.parameters(), lr=0.5)\n",
    "\n",
    "# Data\n",
    "X = tf.tensor([list(x) for x in dataset.xs])\n",
    "y_true = tf.tensor(dataset.ys).view(N_SAMPLES, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818625ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 50\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    \n",
    "    # Zero all grads\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward\n",
    "    y_hat = network.forward(X).sigmoid()\n",
    "\n",
    "    # Compute a loss\n",
    "    loss_per_epoch = tl.binary_cross_entropy(y_true, y_hat)\n",
    "    loss_per_epoch.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record\n",
    "    losses.append(loss_per_epoch.item())\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch}: loss = {loss_per_epoch.item()}\")\n",
    "\n",
    "    if epoch == n_epochs - 1:\n",
    "         print(f\"epoch {epoch + 1}: loss = {loss_per_epoch.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "y_true = y_true.view(y_true.size)\n",
    "y_hat = network.forward(X).sigmoid()\n",
    "y_hat_classes = (y_hat >= 0.5).view(y_hat.size)\n",
    "\n",
    "{\n",
    "    f.__name__: f(y_true=y_true, y_hat=y_hat_classes)\n",
    "    for f in [tm.accuracy, tm.precision, tm.recall]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da11a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "y_true = y_true.view(y_true.size)\n",
    "y_hat = y_hat.view(y_hat.size)\n",
    "\n",
    "tpr, fpr, thresholds = tm.roc_curve(y_true, y_hat, bucket_size=0.01)\n",
    "tpr, fpr = tpr.data.storage, fpr.data.storage\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=110)\n",
    "ax.plot(fpr, tpr, \"-o\", c=\"tab:blue\")\n",
    "ax.plot([0, 1], [0, 1], ls=\"--\", c=\"tab:grey\")\n",
    "ax.set_xlabel(\"fpr\")\n",
    "ax.set_ylabel(\"tpr\")\n",
    "ax.set_title(\"ROC Curve\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed044dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise predictions\n",
    "plot_tensor_predictions(dataset, network);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878f2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minitorch",
   "language": "python",
   "name": "minitorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
