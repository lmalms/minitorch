{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Polygon\n",
    "\n",
    "from minitorch.module import LinearScalarLayer, LinearTensorLayer, ScalarNetwork, TensorNetwork\n",
    "from minitorch.autodiff import Scalar\n",
    "import minitorch.autodiff.tensor_functions as tf\n",
    "from minitorch.optim import SGDOptimizer\n",
    "from minitorch.datasets import Datasets, DatasetTypes\n",
    "from minitorch.operators import sigmoid\n",
    "import minitorch.scalar_metrics as sm\n",
    "import minitorch.scalar_losses as sl\n",
    "import minitorch.tensor_losses as tl\n",
    "import minitorch.tensor_metrics as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e29f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "N_SAMPLES = 50\n",
    "dataset_type = DatasetTypes.diagonal\n",
    "\n",
    "datasets = Datasets.generate_datasets(n_samples=N_SAMPLES)\n",
    "dataset = asdict(datasets)[dataset_type]\n",
    "\n",
    "pos_class = [x for (x, y) in zip(dataset.xs, dataset.ys) if y == 1]\n",
    "neg_class = [x for (x, y) in zip(dataset.xs, dataset.ys) if y == 0]\n",
    "\n",
    "x1_pos, x2_pos = zip(*pos_class)\n",
    "x1_neg, x2_neg = zip(*neg_class)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=110)\n",
    "ax.scatter(list(x1_pos), list(x2_pos), marker=\"x\", c=\"tab:blue\", label=\"class = 1\")\n",
    "ax.scatter(list(x1_neg), list(x2_neg), marker=\"o\", c=\"tab:red\", label=\"class = 0\")\n",
    "ax.legend(loc=1)\n",
    "\n",
    "bottom_left = Polygon([[0, 1], [1, 0], [0, 0]], color=\"tab:blue\", alpha=0.2, lw=0.0)\n",
    "top_right = Polygon([[0, 1], [1, 1], [1, 0]], color=\"tab:red\", alpha=0.2, lw=0.0)\n",
    "ax.add_patch(bottom_left)\n",
    "ax.add_patch(top_right)\n",
    "\n",
    "ax.set_xlabel(\"x1\")\n",
    "ax.set_ylabel(\"x2\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6303c",
   "metadata": {},
   "source": [
    "### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear layer\n",
    "network = LinearScalarLayer(input_dim=2, output_dim=1)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = SGDOptimizer(parameters=network.parameters(), lr=0.75)\n",
    "\n",
    "# Data\n",
    "X = [list(x) for x in dataset.xs]\n",
    "y_true = dataset.ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 200\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    \n",
    "    # Zero all grads\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward\n",
    "    y_hat = network.forward(X)\n",
    "\n",
    "    # Convert to binary class probabilties\n",
    "    y_hat = [[scalar.sigmoid() for scalar in row] for row in y_hat]\n",
    "    y_hat = list(itertools.chain.from_iterable(y_hat))\n",
    "\n",
    "    # Compute a loss\n",
    "    loss_per_epoch = sl.binary_cross_entropy(y_true, y_hat)\n",
    "    loss_per_epoch.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record\n",
    "    losses.append(loss_per_epoch.data)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch}: loss = {loss_per_epoch.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d29f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "y_true = [Scalar(y_t) for y_t in y_true]\n",
    "y_hat = [[scalar.sigmoid() for scalar in row] for row in network.forward(X)]\n",
    "y_hat = list(itertools.chain.from_iterable(y_hat))\n",
    "\n",
    "# Convert to classes using 0.5 threshold\n",
    "y_hat_classes = [Scalar(1.0) if proba.data >= 0.5 else Scalar(0.0) for proba in y_hat]\n",
    "\n",
    "{\n",
    "    f.__name__: f(y_true=y_true, y_hat=y_hat_classes)\n",
    "    for f in [sm.accuracy, sm.precision, sm.recall]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c6597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "tpr, fpr, thresholds = sm.roc_curve(y_true, y_hat, bucket_size=0.025)\n",
    "tpr, fpr = [s.data for s in tpr], [s.data for s in fpr]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=110)\n",
    "ax.plot(fpr, tpr, \"-o\", c=\"tab:blue\")\n",
    "ax.plot([0, 1], [0, 1], ls=\"--\", c=\"tab:grey\")\n",
    "ax.set_xlabel(\"fpr\")\n",
    "ax.set_ylabel(\"tpr\")\n",
    "ax.set_title(\"ROC Curve\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e21f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising predictions\n",
    "fig, ax = plt.subplots(1, 1, dpi=110)\n",
    "ax.scatter(list(x1_pos), list(x2_pos), marker=\"x\", c=\"tab:blue\")\n",
    "ax.scatter(list(x1_neg), list(x2_neg), marker=\"o\", c=\"tab:red\")\n",
    "\n",
    "# Visualise decision boundary\n",
    "\n",
    "bias_positions = list(np.linspace(0, 2, 101))\n",
    "x_range = list(np.linspace(0, 1, 101))\n",
    "\n",
    "for bias_lower, bias_upper in zip(bias_positions, bias_positions[1:]):\n",
    "    \n",
    "    # Create corresponding x2 values for lower\n",
    "    X_lower = [list((x1, bias_lower - x1)) for x1 in x_range]\n",
    "    \n",
    "    # Clamp values to between 0.0 and 1.0\n",
    "    X_lower = [[x1, max(min(x2, 1.0), 0.0)] for (x1, x2) in X_lower]\n",
    "    y_lower = network.forward(X_lower)\n",
    "    y_mean_lower = sigmoid(sum(scalar[0].data for scalar in y_lower) / len(y_lower))\n",
    "\n",
    "    # Create corresponding x2 values for upper\n",
    "    X_upper = [list((x1, bias_upper - x1)) for x1 in x_range]\n",
    "    \n",
    "    # Clamp upper and lower bounds\n",
    "    X_upper = [[x1, max(min(x2, 1.0), 0.0)] for (x1, x2) in X_upper]\n",
    "    y_upper = network.forward(X_upper)\n",
    "    y_mean_upper = sigmoid(sum(scalar[0].data for scalar in y_upper) / len(y_upper))\n",
    "\n",
    "    # Plot and fill    \n",
    "    ax.fill_between(\n",
    "        x_range,\n",
    "        [x2 for (_, x2) in X_lower],\n",
    "        [x2 for (_, x2) in X_upper],\n",
    "        alpha=(y_mean_lower - 0.5) if y_mean_lower >= 0.5 else (0.5 - y_mean_lower),\n",
    "        color=\"tab:blue\" if y_mean_lower >= 0.5 else \"tab:red\",\n",
    "        lw=0.01\n",
    "    )\n",
    "    \n",
    "\n",
    "ax.set_xlabel(\"x1\")\n",
    "ax.set_ylabel(\"x2\")\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83a0f4",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa58f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear layer\n",
    "network = TensorNetwork(input_dim=2, hidden_dim = 5, output_dim=1)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = SGDOptimizer(parameters=network.parameters(), lr=0.5)\n",
    "\n",
    "# Data\n",
    "X = tf.tensor([list(x) for x in dataset.xs])\n",
    "y_true = tf.tensor(dataset.ys).view(N_SAMPLES, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac50529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 200\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    \n",
    "    # Zero all grads\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward\n",
    "    y_hat = network.forward(X).sigmoid()\n",
    "\n",
    "    # Compute a loss\n",
    "    loss_per_epoch = tl.binary_cross_entropy(y_true, y_hat)\n",
    "    loss_per_epoch.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record\n",
    "    losses.append(loss_per_epoch.item())\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch}: loss = {loss_per_epoch.item()}\")\n",
    "\n",
    "    if epoch == (n_epochs - 1):\n",
    "        print(f\"epoch {epoch + 1}: loss = {loss_per_epoch.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0123d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "y_true = y_true.view(y_true.size)\n",
    "y_hat = network.forward(X).sigmoid()\n",
    "y_hat_classes = (y_hat >= 0.5).view(y_hat.size)\n",
    "\n",
    "{\n",
    "    f.__name__: f(y_true=y_true, y_hat=y_hat_classes)\n",
    "    for f in [tm.accuracy, tm.precision, tm.recall]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b0fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minitorch",
   "language": "python",
   "name": "minitorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
